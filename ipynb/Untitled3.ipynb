{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [0, 2], [1, 0], [1, 2], [1, 3]]\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor(3.2651)\n",
      "tensor(1.4320)\n",
      "tensor(1.3535)\n",
      "tensor(1.3446)\n",
      "tensor(1.3422)\n",
      "tensor(1.3413)\n",
      "tensor(1.3408)\n",
      "tensor(1.3406)\n",
      "tensor(1.3405)\n",
      "tensor(1.3405)\n"
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "#Generating desired pair of inputs and targets\n",
    "#Empty list that collects input and target in pairs\n",
    "inp_target_list = []         \n",
    "    \n",
    "for i in range(26):\n",
    "    temp = []\n",
    "    a, b, c, d = i- 2, i - 1, i + 1, i + 2  #targets for input i\n",
    "    temp.extend([a, b, c, d])\n",
    "#keep targets within range of 0 to 25\n",
    "    for j in range(4):\n",
    "        if temp[j] >=0 and temp[j] <=25:\n",
    "            inp_target_list.append([i, temp[j]])\n",
    "print(inp_target_list[:5])\n",
    "#[[0, 1], [0, 2], [1, 0], [1, 2], [1, 3]]\n",
    "#Get one hot vectors for all inputs\n",
    "#Initiate tensor with 0â€™s that holds all inputs in inp_target pairs\n",
    "inp_tensor= torch.zeros(len(inp_target_list), 26)\n",
    "#Substitute 1 for 0, at position indicated by respective input   \n",
    "for i in range(len(inp_tensor)):\n",
    "    inp_tensor[i, np.array(inp_target_list)[i, 0]] =1\n",
    "#One_hot for 0 or letter 'a'\n",
    "print(inp_tensor[0]) \n",
    "#tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "#Create Network \n",
    "#2 fully connected layers with NO bias\n",
    "#Embedding dimension is 10\n",
    "#Softmax is implemented using loss criterion (nn.CrossEntropyLoss())\n",
    "fc1 = nn.Linear(26, 10, bias = False)\n",
    "fc2 = nn.Linear(10, 26, bias = False)\n",
    "params = list(fc1.parameters()) + list(fc2.parameters())\n",
    "LR = 0.001  #Learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params, lr = LR)\n",
    "#Train\n",
    "#Define inputs and target tensors\n",
    "inp_tensor = inp_tensor\n",
    "target_tensor = torch.tensor(inp_target_list)[:, 1]\n",
    "losses = []\n",
    "for i in range(10000):\n",
    "    out_1 = fc1(torch.Tensor(inp_tensor)) #hidden layer\n",
    "    out_2 = fc2(out_1)                    #Score matrix\n",
    "    optimizer.zero_grad()                 #Flushing gradients \n",
    "    \n",
    "    loss = criterion(out_2,               target_tensor.long().view(out_2.shape[0],))#Apply Softmax, get loss \n",
    "    \n",
    "    loss.backward()                        #Getting grads\n",
    "    optimizer.step()                       #Correcting parameters\n",
    "    if i % 1000 == 0:\n",
    "        losses.append(loss.item())\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py374",
   "language": "python",
   "name": "py374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
