{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training f(5): 0.0\n",
      "ephoc:0, w:1.200\n",
      "ephoc:2, w:1.872\n",
      "ephoc:4, w:1.980\n",
      "ephoc:6, w:1.997\n",
      "ephoc:8, w:1.999\n",
      "ephoc:10, w:2.000\n",
      "ephoc:12, w:2.000\n",
      "ephoc:14, w:2.000\n",
      "ephoc:16, w:2.000\n",
      "ephoc:18, w:2.000\n",
      "prediction after training f(5): 9.99999977350235\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "def gradient(x, y, y_predicted):\n",
    "    return np.dot(2*x, y_predicted-y).mean()\n",
    "\n",
    "print(\"prediction before training f(5):\", forward(5))\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(X)\n",
    "    l = loss(Y, y_pred)\n",
    "    dl = gradient(X, Y, y_pred)\n",
    "    w -= learning_rate * dl\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f'ephoc:{epoch}, w:{w:.3f}')\n",
    "\n",
    "print(\"prediction after training f(5):\", forward(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pytorch for backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., requires_grad=True)\n",
      "prediction before training f(5): 0.0\n",
      "ephoc:0, w:0.300, loss:30.000\n",
      "ephoc:10, w:1.665, loss:1.163\n",
      "ephoc:20, w:1.934, loss:0.045\n",
      "ephoc:30, w:1.987, loss:0.002\n",
      "ephoc:40, w:1.997, loss:0.000\n",
      "ephoc:50, w:1.999, loss:0.000\n",
      "ephoc:60, w:2.000, loss:0.000\n",
      "ephoc:70, w:2.000, loss:0.000\n",
      "ephoc:80, w:2.000, loss:0.000\n",
      "ephoc:90, w:2.000, loss:0.000\n",
      "prediction after training f(5): 9.999998\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, requires_grad=True)\n",
    "print(w)\n",
    "\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "def loss(y, y_predicted):\n",
    "    return((y_predicted-y)**2).mean()\n",
    "\n",
    "print(\"prediction before training f(5):\", forward(5).data.detach().numpy())\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(X)\n",
    "    l = loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "    \n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'ephoc:{epoch}, w:{w:.3f}, loss:{l:.3f}')\n",
    "\n",
    "print(\"prediction after training f(5):\", forward(5).data.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pytorch for loss and optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., requires_grad=True)\n",
      "prediction before training f(5): 0.0\n",
      "ephoc:0, w:0.300, loss:30.000\n",
      "ephoc:10, w:1.665, loss:1.163\n",
      "ephoc:20, w:1.934, loss:0.045\n",
      "ephoc:30, w:1.987, loss:0.002\n",
      "ephoc:40, w:1.997, loss:0.000\n",
      "ephoc:50, w:1.999, loss:0.000\n",
      "ephoc:60, w:2.000, loss:0.000\n",
      "ephoc:70, w:2.000, loss:0.000\n",
      "ephoc:80, w:2.000, loss:0.000\n",
      "ephoc:90, w:2.000, loss:0.000\n",
      "prediction after training f(5): 9.999998\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, requires_grad=True)\n",
    "print(w)\n",
    "\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
    "\n",
    "print(\"prediction before training f(5):\", forward(5).data.detach().numpy())\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(X)\n",
    "    l = loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'ephoc:{epoch}, w:{w:.3f}, loss:{l:.3f}')\n",
    "\n",
    "print(\"prediction after training f(5):\", forward(5).data.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pytorch for forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training f(5): 3.102421283721924\n",
      "ephoc:0, w:0.640, loss:12.140\n",
      "ephoc:10, w:1.442, loss:0.548\n",
      "ephoc:20, w:1.581, loss:0.234\n",
      "ephoc:30, w:1.613, loss:0.213\n",
      "ephoc:40, w:1.628, loss:0.201\n",
      "ephoc:50, w:1.639, loss:0.189\n",
      "ephoc:60, w:1.650, loss:0.178\n",
      "ephoc:70, w:1.660, loss:0.168\n",
      "ephoc:80, w:1.670, loss:0.158\n",
      "ephoc:90, w:1.680, loss:0.149\n",
      "prediction before training f(5): 9.358319282531738\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "print(\"prediction before training f(5):\", model(X_test).item())\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = model(X)\n",
    "    l = loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'ephoc:{epoch}, w:{w[0][0].item():.3f}, loss:{l:.3f}')\n",
    "\n",
    "print(\"prediction before training f(5):\", model(X_test).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing our own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.])\n",
      "prediction before training f(5): 3.2198257446289062\n",
      "ephoc:0, w:0.678, loss:11.883\n",
      "ephoc:10, w:1.472, loss:0.510\n",
      "ephoc:20, w:1.609, loss:0.204\n",
      "ephoc:30, w:1.640, loss:0.185\n",
      "ephoc:40, w:1.654, loss:0.174\n",
      "ephoc:50, w:1.664, loss:0.163\n",
      "ephoc:60, w:1.674, loss:0.154\n",
      "ephoc:70, w:1.684, loss:0.145\n",
      "ephoc:80, w:1.693, loss:0.137\n",
      "ephoc:90, w:1.702, loss:0.129\n",
      "prediction after training f(5): 9.403336524963379\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "class MyLinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyLinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "model = MyLinearRegression(input_size, output_size)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "print(X_test)\n",
    "print(\"prediction before training f(5):\", model(X_test).item())\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = model(X)\n",
    "    l = loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'ephoc:{epoch}, w:{w[0][0].item():.3f}, loss:{l:.3f}')\n",
    "\n",
    "print(\"prediction after training f(5):\", model(X_test).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing logistic regression with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2f8c0b10>]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0) prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "#sacle\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "#prepare data for pytorch\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# 1) model\n",
    "# f = wx + b, sigmoid at the end\n",
    "class MylogisticRegression(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(MylogisticRegression, self).__init__()\n",
    "        self.Linear = nn.Linear(input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.Linear(x))\n",
    "        return y_predicted\n",
    "\n",
    "model = MylogisticRegression(input_features=n_features)\n",
    "        \n",
    "# 2) loss and optimizer\n",
    "loss = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_iters = 100\n",
    "training_loss = []\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = model(X_train)\n",
    "    l = loss(y_pred, y_train)\n",
    "    \n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    training_loss.append(l.item())\n",
    "    \n",
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: tensor(0.9211)\n"
     ]
    }
   ],
   "source": [
    "# 4)evaluation\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(X_test)\n",
    "    pred_cls = pred.round()\n",
    "    acc = pred_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(\"accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dataloader with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# get the data from https://github.com/python-engineer/pytorchTutorial\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        #loading data\n",
    "        xy = np.loadtxt(\"/Users/fahimehb/Documents/GNN/dat/wine/wine.csv\", \n",
    "                        delimiter=\",\", \n",
    "                        dtype=np.float32, \n",
    "                        skiprows=1)\n",
    "        \n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) #n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples \n",
    "    \n",
    "\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic.acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Acl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid.phenols</th>\n",
       "      <th>Proanth</th>\n",
       "      <th>Color.int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "0       1    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
       "1       1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2       1    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3       1    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4       1    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "..    ...      ...         ...   ...   ...  ...      ...         ...   \n",
       "173     3    13.71        5.65  2.45  20.5   95     1.68        0.61   \n",
       "174     3    13.40        3.91  2.48  23.0  102     1.80        0.75   \n",
       "175     3    13.27        4.28  2.26  20.0  120     1.59        0.69   \n",
       "176     3    13.17        2.59  2.37  20.0  120     1.65        0.68   \n",
       "177     3    14.13        4.10  2.74  24.5   96     2.05        0.76   \n",
       "\n",
       "     Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "0                    0.28     2.29       5.64  1.04  3.92     1065  \n",
       "1                    0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                    0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                    0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                    0.39     1.82       4.32  1.04  2.93      735  \n",
       "..                    ...      ...        ...   ...   ...      ...  \n",
       "173                  0.52     1.06       7.70  0.64  1.74      740  \n",
       "174                  0.43     1.41       7.30  0.70  1.56      750  \n",
       "175                  0.43     1.35      10.20  0.59  1.56      835  \n",
       "176                  0.53     1.46       9.30  0.60  1.62      840  \n",
       "177                  0.56     1.35       9.20  0.61  1.60      560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/Users/fahimehb/Documents/GNN/dat/wine/wine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2470e+01, 1.5200e+00, 2.2000e+00, 1.9000e+01, 1.6200e+02, 2.5000e+00,\n",
      "         2.2700e+00, 3.2000e-01, 3.2800e+00, 2.6000e+00, 1.1600e+00, 2.6300e+00,\n",
      "         9.3700e+02],\n",
      "        [1.1450e+01, 2.4000e+00, 2.4200e+00, 2.0000e+01, 9.6000e+01, 2.9000e+00,\n",
      "         2.7900e+00, 3.2000e-01, 1.8300e+00, 3.2500e+00, 8.0000e-01, 3.3900e+00,\n",
      "         6.2500e+02],\n",
      "        [1.3200e+01, 1.7800e+00, 2.1400e+00, 1.1200e+01, 1.0000e+02, 2.6500e+00,\n",
      "         2.7600e+00, 2.6000e-01, 1.2800e+00, 4.3800e+00, 1.0500e+00, 3.4000e+00,\n",
      "         1.0500e+03],\n",
      "        [1.3730e+01, 4.3600e+00, 2.2600e+00, 2.2500e+01, 8.8000e+01, 1.2800e+00,\n",
      "         4.7000e-01, 5.2000e-01, 1.1500e+00, 6.6200e+00, 7.8000e-01, 1.7500e+00,\n",
      "         5.2000e+02]]) tensor([[2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "batchsize=4\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batchsize, shuffle=True, num_workers=2)\n",
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)\n",
    "#since we have a batchsize 4, we will see the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "epoch:1/2, step:5/45, inputs:torch.Size([4, 13])\n",
      "epoch:1/2, step:10/45, inputs:torch.Size([4, 13])\n",
      "epoch:1/2, step:15/45, inputs:torch.Size([4, 13])\n",
      "epoch:1/2, step:20/45, inputs:torch.Size([4, 13])\n",
      "epoch:1/2, step:25/45, inputs:torch.Size([4, 13])\n",
      "epoch:1/2, step:30/45, inputs:torch.Size([4, 13])\n",
      "epoch:1/2, step:35/45, inputs:torch.Size([4, 13])\n",
      "epoch:1/2, step:40/45, inputs:torch.Size([4, 13])\n",
      "epoch:1/2, step:45/45, inputs:torch.Size([2, 13])\n",
      "epoch:2/2, step:5/45, inputs:torch.Size([4, 13])\n",
      "epoch:2/2, step:10/45, inputs:torch.Size([4, 13])\n",
      "epoch:2/2, step:15/45, inputs:torch.Size([4, 13])\n",
      "epoch:2/2, step:20/45, inputs:torch.Size([4, 13])\n",
      "epoch:2/2, step:25/45, inputs:torch.Size([4, 13])\n",
      "epoch:2/2, step:30/45, inputs:torch.Size([4, 13])\n",
      "epoch:2/2, step:35/45, inputs:torch.Size([4, 13])\n",
      "epoch:2/2, step:40/45, inputs:torch.Size([4, 13])\n",
      "epoch:2/2, step:45/45, inputs:torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/batchsize) #number of iterations in each epoch\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, label) in enumerate(dataloader):\n",
    "        #forward, backward, update gradient\n",
    "        if (i+1) % 5 == 0 :\n",
    "            print(f'epoch:{epoch+1}/{num_epochs}, step:{i+1}/{n_iterations}, inputs:{inputs.shape}',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using transform with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        #loading data\n",
    "        xy = np.loadtxt(\"/Users/fahimehb/Documents/GNN/dat/wine/wine.csv\", \n",
    "                        delimiter=\",\", \n",
    "                        dtype=np.float32, \n",
    "                        skiprows=1)\n",
    "        \n",
    "        self.x = xy[:, 1:]\n",
    "        self.y = xy[:, [0]] #n_samples, 1\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples \n",
    "    \n",
    "\n",
    "# lets implement a transform\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(target)\n",
    "    \n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
       "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
       "         1.0650e+03]), tensor([1.]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= WineDataset(transform=ToTensor())\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
       "        3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
       "        1.065e+03], dtype=float32), array([1.], dtype=float32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= WineDataset(transform=None)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
       "         6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
       "         2.1300e+03]), tensor([1.]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax and Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mysoftmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.6590, 0.2424, 0.0986])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([2., 1., 0.1])\n",
    "output = Mysoftmax(x)\n",
    "print(\"softmax numpy:\", output)\n",
    "x = torch.tensor([2., 1., 0.1])\n",
    "torch.softmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyCrossEntropy(actual, predicted):\n",
    "    return -np.sum(actual * np.log(predicted)) #We did not normalize it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1:0.3567\n",
      "Loss 2:2.3026\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([1, 0, 0])\n",
    "\n",
    "y_pred_good = np.array([0.7, 0.2, 0.1]) #softmax applied\n",
    "y_pred_bad = np.array([0.1, 0.3, 0.6]) #softmax applied\n",
    "\n",
    "l1 = MyCrossEntropy(Y, y_pred_good)\n",
    "l2 = MyCrossEntropy(Y, y_pred_bad)\n",
    "\n",
    "print(f'Loss 1:{l1:.4f}')\n",
    "print(f'Loss 2:{l2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For only one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1:0.4170\n",
      "Loss 2:1.8406\n"
     ]
    }
   ],
   "source": [
    "Y = torch.tensor([0])# Y is not anymore one hot, it is the label\n",
    "# n_sample x nclasses\n",
    "\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]]) #must not have softmax\n",
    "Y_pred_bad = torch.tensor([[.5, 2., 0.3]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(f'Loss 1:{l1.item():.4f}')\n",
    "print(f'Loss 2:{l2.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "_, prediction1 = torch.max(Y_pred_good, dim=1)\n",
    "_, prediction2 = torch.max(Y_pred_bad, dim=1)\n",
    "\n",
    "print(prediction1, prediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For 3 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1:0.3392\n",
      "Loss 2:2.2584\n",
      "tensor([2, 0, 1]) tensor([0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "Y = torch.tensor([2, 0, 1]) \n",
    "\n",
    "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 0.1, 0.5], [0.1, 2., 0.5]])\n",
    "Y_pred_bad = torch.tensor([[2., 0.5, .1], [0.1, 1.0, 2.1], [3.0, 1.0, 0.1]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(f'Loss 1:{l1.item():.4f}')\n",
    "print(f'Loss 2:{l2.item():.4f}')\n",
    "\n",
    "_, prediction1 = torch.max(Y_pred_good, dim=1)\n",
    "_, prediction2 = torch.max(Y_pred_bad, dim=1)\n",
    "\n",
    "print(prediction1, prediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST pytorch deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyperparameter\n",
    "input_size = 784 #28x28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, \n",
    "                                           transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, \n",
    "                                           transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/2, steps:100/600, loss:0.4618\n",
      "epoch: 1/2, steps:200/600, loss:0.3161\n",
      "epoch: 1/2, steps:300/600, loss:0.3195\n",
      "epoch: 1/2, steps:400/600, loss:0.4161\n",
      "epoch: 1/2, steps:500/600, loss:0.3166\n",
      "epoch: 1/2, steps:600/600, loss:0.2503\n",
      "epoch: 2/2, steps:100/600, loss:0.1495\n",
      "epoch: 2/2, steps:200/600, loss:0.3153\n",
      "epoch: 2/2, steps:300/600, loss:0.1372\n",
      "epoch: 2/2, steps:400/600, loss:0.2075\n",
      "epoch: 2/2, steps:500/600, loss:0.1383\n",
      "epoch: 2/2, steps:600/600, loss:0.2236\n",
      "accuracy:0.93\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "        \n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # shape of data 100 x 1 x 28 x 28\n",
    "        # we have to make it 100 x 784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch: {epoch+1}/{num_epochs}, steps:{i+1}/{n_total_steps}, loss:{loss.item():.4f}')\n",
    "            \n",
    "    \n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct = (predictions == labels).sum().item()\n",
    "acc = 100 * n_correct / n_samples\n",
    "print(f'accuracy:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py374",
   "language": "python",
   "name": "py374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
