{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling BaseAny2VecModel\n",
      " In the BaseWordEmbeddingsModel\n",
      "I am here!\n",
      "I am in Word2VecVocab class\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import itertools\n",
    "import gzip\n",
    "\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "from numpy import exp, dot,  sum as np_sum\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "from gensim import matutils \n",
    "\n",
    "from cell import utils\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from cell import analysis\n",
    "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file=\"reviews_data.txt.gz\"\n",
    "input_file = \"/Users/fahimehb/Downloads/\"\n",
    "\n",
    "with gzip.open (input_file+'reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-31 20:05:27,919 : INFO : reading file /Users/fahimehb/Downloads/reviews_data.txt.gz...this may take a while\n",
      "2020-03-31 20:05:27,921 : INFO : read 0 reviews\n",
      "2020-03-31 20:05:30,379 : INFO : read 10000 reviews\n",
      "2020-03-31 20:05:32,890 : INFO : read 20000 reviews\n",
      "2020-03-31 20:05:35,671 : INFO : read 30000 reviews\n",
      "2020-03-31 20:05:38,676 : INFO : read 40000 reviews\n",
      "2020-03-31 20:05:41,532 : INFO : read 50000 reviews\n",
      "2020-03-31 20:05:44,378 : INFO : read 60000 reviews\n",
      "2020-03-31 20:05:46,598 : INFO : read 70000 reviews\n",
      "2020-03-31 20:05:48,629 : INFO : read 80000 reviews\n",
      "2020-03-31 20:05:50,798 : INFO : read 90000 reviews\n",
      "2020-03-31 20:05:52,855 : INFO : read 100000 reviews\n",
      "2020-03-31 20:05:55,265 : INFO : read 110000 reviews\n",
      "2020-03-31 20:05:57,347 : INFO : read 120000 reviews\n",
      "2020-03-31 20:05:59,496 : INFO : read 130000 reviews\n",
      "2020-03-31 20:06:01,745 : INFO : read 140000 reviews\n",
      "2020-03-31 20:06:04,326 : INFO : read 150000 reviews\n",
      "2020-03-31 20:06:06,464 : INFO : read 160000 reviews\n",
      "2020-03-31 20:06:08,559 : INFO : read 170000 reviews\n",
      "2020-03-31 20:06:10,795 : INFO : read 180000 reviews\n",
      "2020-03-31 20:06:12,956 : INFO : read 190000 reviews\n",
      "2020-03-31 20:06:15,348 : INFO : read 200000 reviews\n",
      "2020-03-31 20:06:17,603 : INFO : read 210000 reviews\n",
      "2020-03-31 20:06:19,896 : INFO : read 220000 reviews\n",
      "2020-03-31 20:06:22,005 : INFO : read 230000 reviews\n",
      "2020-03-31 20:06:24,897 : INFO : read 240000 reviews\n",
      "2020-03-31 20:06:27,038 : INFO : read 250000 reviews\n",
      "2020-03-31 20:06:28,191 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "            yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "# read the tokenized reviews into a list\n",
    "# each review item becomes a serries of words\n",
    "# so this becomes a list of lists\n",
    "corpus = list (read_input (input_file + data_file))\n",
    "logging.info (\"Done reading data file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random, math\n",
    "\n",
    "def subsample_frequent_words(corpus):\n",
    "    filtered_corpus = []\n",
    "    word_counts = dict(Counter(list(itertools.chain.from_iterable(corpus))))\n",
    "    sum_word_counts = sum(list(word_counts.values()))\n",
    "    word_counts = {word: word_counts[word]/float(sum_word_counts) for word in word_counts}\n",
    "    for text in corpus:\n",
    "        filtered_corpus.append([])\n",
    "        for word in text:\n",
    "            if random.random() < (1+math.sqrt(word_counts[word] * 1e3)) * 1e-3 / float(word_counts[word]):\n",
    "                filtered_corpus[-1].append(word)\n",
    "    return filtered_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = subsample_frequent_words(corpus)\n",
    "#corpus = corpus[0:1000]\n",
    "from cell import utils\n",
    "corpus = utils.read_list_of_lists_from_csv(\"/Users/fahimehb/Documents/NPP_GNN_project/dat/walks/VISp/test_layer/Undirected_Weighted_node2vec/l_10000_p_1_q_1/\", \"walk0.csv\")\n",
    "\n",
    "vocabulary = set(itertools.chain.from_iterable(corpus))\n",
    "\n",
    "word_to_index = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "index_to_word = {idx: w for (idx, w) in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# context_tuple_list = []\n",
    "# w = 2\n",
    "\n",
    "# for text in corpus:\n",
    "#     for i, word in enumerate(text):\n",
    "#         first_context_word_index = max(0,i-w)\n",
    "#         last_context_word_index = min(i+w, len(text))\n",
    "#         for j in range(first_context_word_index, last_context_word_index):\n",
    "#             if i!=j:\n",
    "#                 context_tuple_list.append((word, text[j]))\n",
    "# print(\"There are {} pairs of target and context words\".format(len(context_tuple_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn  as  nn\n",
    "# import torch.autograd as autograd\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class Word2Vec(nn.Module):\n",
    "\n",
    "#     def __init__(self, embedding_size, vocab_size):\n",
    "#         super(Word2Vec, self).__init__()\n",
    "#         self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "#         self.linear = nn.Linear(embedding_size, vocab_size)\n",
    "        \n",
    "#     def forward(self, context_word):\n",
    "#         emb = self.embeddings(context_word)\n",
    "#         hidden = self.linear(emb)\n",
    "#         out = F.log_softmax(hidden)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience=5, min_percent_gain=0.1):\n",
    "        self.patience = patience\n",
    "        self.loss_list = []\n",
    "        self.min_percent_gain = min_percent_gain / 100.\n",
    "        \n",
    "    def update_loss(self, loss):\n",
    "        self.loss_list.append(loss)\n",
    "        if len(self.loss_list) > self.patience:\n",
    "            del self.loss_list[0]\n",
    "    \n",
    "    def stop_training(self):\n",
    "        if len(self.loss_list) == 1:\n",
    "            return False\n",
    "        gain = (max(self.loss_list) - min(self.loss_list)) / max(self.loss_list)\n",
    "        print(\"Loss gain: {}%\".format(round(100*gain,2)))\n",
    "        if gain < self.min_percent_gain:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary_size = len(vocabulary)\n",
    "\n",
    "# net = Word2Vec(embedding_size=2, vocab_size=vocabulary_size)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(net.parameters())\n",
    "# early_stopping = EarlyStopping()\n",
    "# context_tensor_list = []\n",
    "\n",
    "# for target, context in context_tuple_list:\n",
    "#     target_tensor = autograd.Variable(torch.LongTensor([word_to_index[target]]))\n",
    "#     context_tensor = autograd.Variable(torch.LongTensor([word_to_index[context]]))\n",
    "#     context_tensor_list.append((target_tensor, context_tensor))\n",
    "    \n",
    "# while True:\n",
    "#     losses = []\n",
    "#     for target_tensor, context_tensor in context_tensor_list:\n",
    "#         net.zero_grad()\n",
    "#         log_probs = net(context_tensor)\n",
    "#         loss = loss_function(log_probs, target_tensor)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         losses.append(loss.data)\n",
    "#         print(loss)\n",
    "#     print(\"Loss: \", np.mean(losses))\n",
    "#     early_stopping.update_loss(np.mean(losses))\n",
    "#     if early_stopping.stop_training():\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_batches(context_tuple_list, batch_size=100):\n",
    "    random.shuffle(context_tuple_list)\n",
    "    batches = []\n",
    "    batch_target, batch_context, batch_negative = [], [], []\n",
    "    for i in range(len(context_tuple_list)):\n",
    "        batch_target.append(word_to_index[context_tuple_list[i][0]])\n",
    "        batch_context.append(word_to_index[context_tuple_list[i][1]])\n",
    "        batch_negative.append([word_to_index[w] for w in context_tuple_list[i][2]])\n",
    "        if (i+1) % batch_size == 0 or i == len(context_tuple_list)-1:\n",
    "            tensor_target = autograd.Variable(torch.from_numpy(np.array(batch_target)).long())\n",
    "            tensor_context = autograd.Variable(torch.from_numpy(np.array(batch_context)).long())\n",
    "            tensor_negative = autograd.Variable(torch.from_numpy(np.array(batch_negative)).long())\n",
    "            batches.append((tensor_target, tensor_context, tensor_negative))\n",
    "            batch_target, batch_context, batch_negative = [], [], []\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import multinomial\n",
    "\n",
    "def sample_negative(sample_size):\n",
    "    sample_probability = {}\n",
    "    word_counts = dict(Counter(list(itertools.chain.from_iterable(corpus))))\n",
    "    normalizing_factor = sum([v**0.75 for v in word_counts.values()])\n",
    "    for word in word_counts:\n",
    "        sample_probability[word] = word_counts[word]**0.75 / normalizing_factor\n",
    "    words = np.array(list(word_counts.keys()))\n",
    "    while True:\n",
    "        word_list = []\n",
    "        sampled_index = np.array(multinomial(sample_size, list(sample_probability.values())))\n",
    "        for index, count in enumerate(sampled_index):\n",
    "            for _ in range(count):\n",
    "                 word_list.append(words[index])\n",
    "        yield word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[len(corpus[i]) for i in range(len(corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "There are 2789628 pairs of target and context words\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "context_tuple_list = []\n",
    "w = 2\n",
    "negative_samples = sample_negative(4)\n",
    "\n",
    "k =0 \n",
    "for text in corpus:\n",
    "    print(len(text))\n",
    "    for i, word in enumerate(text):\n",
    "        first_context_word_index = max(0,i-w)\n",
    "        last_context_word_index = min(i+w, len(text))\n",
    "        for j in range(first_context_word_index, last_context_word_index):\n",
    "            if i!=j:\n",
    "                context_tuple_list.append((word, text[j], next(negative_samples)))\n",
    "print(\"There are {} pairs of target and context words\".format(len(context_tuple_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context_tuple_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Word2Vec(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, vocab_size):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.embeddings_target = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.embeddings_context = nn.Embedding(vocab_size, embedding_size)\n",
    "\n",
    "    def forward(self, target_word, context_word, negative_example):\n",
    "        emb_target = self.embeddings_target(target_word)\n",
    "        emb_context = self.embeddings_context(context_word)\n",
    "        emb_product = torch.mul(emb_target, emb_context)\n",
    "        emb_product = torch.sum(emb_product, dim=1)\n",
    "        out = torch.sum(F.logsigmoid(emb_product))\n",
    "        emb_negative = self.embeddings_context(negative_example)\n",
    "        emb_product = torch.bmm(emb_negative, emb_target.unsqueeze(2))\n",
    "        emb_product = torch.sum(emb_product, dim=1)\n",
    "        out += torch.sum(F.logsigmoid(-emb_product))\n",
    "        return -out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4459.56\n",
      "Loss:  2306.8613\n",
      "Loss gain: 48.27%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3e70dfce611b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcontext_tuple_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_tuple_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_tuple_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-96d9bcda3ed8>\u001b[0m in \u001b[0;36mget_batches\u001b[0;34m(context_tuple_list, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_tuple_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_tuple_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_negative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py374/lib/python3.7/random.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(self, x, random)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# pick an element in x[:i+1] with which to exchange x[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py374/lib/python3.7/random.py\u001b[0m in \u001b[0;36m_randbelow\u001b[0;34m(self, n, int, maxsize, type, Method, BuiltinMethod)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetrandbits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# 0 <= r < 2**k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetrandbits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# There's an overridden random() method but no new getrandbits() method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "net = Word2Vec(embedding_size=10, vocab_size=vocabulary_size)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "early_stopping = EarlyStopping(patience=5, min_percent_gain=1)\n",
    "\n",
    "while True:\n",
    "    losses = []\n",
    "    context_tuple_batches = get_batches(context_tuple_list, batch_size=2000)\n",
    "    for i in range(len(context_tuple_batches)):\n",
    "        net.zero_grad()\n",
    "        target_tensor, context_tensor, negative_tensor = context_tuple_batches[i]\n",
    "        loss = net(target_tensor, context_tensor, negative_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data)\n",
    "        #print(loss)\n",
    "    print(\"Loss: \", np.mean(losses))\n",
    "    early_stopping.update_loss(np.mean(losses))\n",
    "    if early_stopping.stop_training():\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_closest_word(word, topn=5):\n",
    "    word_distance = []\n",
    "    emb = net.embeddings_target\n",
    "    pdist = nn.PairwiseDistance()\n",
    "    i = word_to_index[word]\n",
    "    lookup_tensor_i = torch.tensor([i], dtype=torch.long)\n",
    "    v_i = emb(lookup_tensor_i)\n",
    "    for j in range(len(vocabulary)):\n",
    "        if j != i:\n",
    "            lookup_tensor_j = torch.tensor([j], dtype=torch.long)\n",
    "            v_j = emb(lookup_tensor_j)\n",
    "            word_distance.append((index_to_word[j], float(pdist(v_i, v_j))))\n",
    "    word_distance.sort(key=lambda x: x[1])\n",
    "    return word_distance[:topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('midnight', 1.003892183303833),\n",
       " ('appeared', 1.230124592781067),\n",
       " ('provide', 1.2656170129776),\n",
       " ('advance', 1.296667456626892),\n",
       " ('upset', 1.3263983726501465)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_word(\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = net.embeddings_target.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8684, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_data = preprocessing.StandardScaler().fit_transform(vectors)\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(scaled_data)\n",
    "pca_data = pca.transform(scaled_data)\n",
    "\n",
    "per_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(x=range(1, len(per_var)+1), height=per_var, tick_label= labels)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the original example text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_data = preprocessing.StandardScaler().fit_transform(vectors)\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(scaled_data)\n",
    "pca_data = pca.transform(scaled_data)\n",
    "\n",
    "per_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(x=range(1, len(per_var)+1), height=per_var, tick_label= labels)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cldf from: //Users/fahimehb/Documents/NPP_GNN_project/dat/cl_df_VISp_annotation.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dendcluster_id</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>colors</th>\n",
       "      <th>cluster_color</th>\n",
       "      <th>subclass_id</th>\n",
       "      <th>subclass_label</th>\n",
       "      <th>subclass_color</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class_label</th>\n",
       "      <th>class_color</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>L2/3 IT VISp Rrad</td>\n",
       "      <td>#D9F077</td>\n",
       "      <td>#D9F077</td>\n",
       "      <td>7</td>\n",
       "      <td>L2/3 IT</td>\n",
       "      <td>#94D9A1</td>\n",
       "      <td>2</td>\n",
       "      <td>Glutamatergic</td>\n",
       "      <td>#27AAE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L2/3 IT VISp Adamts2</td>\n",
       "      <td>#A6E6A9</td>\n",
       "      <td>#A6E6A9</td>\n",
       "      <td>7</td>\n",
       "      <td>L2/3 IT</td>\n",
       "      <td>#94D9A1</td>\n",
       "      <td>2</td>\n",
       "      <td>Glutamatergic</td>\n",
       "      <td>#27AAE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L2/3 IT VISp Agmat</td>\n",
       "      <td>#7AE6AB</td>\n",
       "      <td>#7AE6AB</td>\n",
       "      <td>7</td>\n",
       "      <td>L2/3 IT</td>\n",
       "      <td>#94D9A1</td>\n",
       "      <td>2</td>\n",
       "      <td>Glutamatergic</td>\n",
       "      <td>#27AAE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>L4 IT VISp Rspo1</td>\n",
       "      <td>#00979D</td>\n",
       "      <td>#00979D</td>\n",
       "      <td>8</td>\n",
       "      <td>L4</td>\n",
       "      <td>#00979D</td>\n",
       "      <td>2</td>\n",
       "      <td>Glutamatergic</td>\n",
       "      <td>#27AAE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>L5 IT VISp Hsd11b1 Endou</td>\n",
       "      <td>#00DDC5</td>\n",
       "      <td>#00DDC5</td>\n",
       "      <td>9</td>\n",
       "      <td>L5 IT</td>\n",
       "      <td>#008A61</td>\n",
       "      <td>2</td>\n",
       "      <td>Glutamatergic</td>\n",
       "      <td>#27AAE1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dendcluster_id             cluster_label   colors cluster_color  \\\n",
       "cluster_id                                                                    \n",
       "0                        1         L2/3 IT VISp Rrad  #D9F077       #D9F077   \n",
       "1                        2      L2/3 IT VISp Adamts2  #A6E6A9       #A6E6A9   \n",
       "2                        3        L2/3 IT VISp Agmat  #7AE6AB       #7AE6AB   \n",
       "3                        7          L4 IT VISp Rspo1  #00979D       #00979D   \n",
       "4                        8  L5 IT VISp Hsd11b1 Endou  #00DDC5       #00DDC5   \n",
       "\n",
       "            subclass_id subclass_label subclass_color  class_id  \\\n",
       "cluster_id                                                        \n",
       "0                     7        L2/3 IT        #94D9A1         2   \n",
       "1                     7        L2/3 IT        #94D9A1         2   \n",
       "2                     7        L2/3 IT        #94D9A1         2   \n",
       "3                     8             L4        #00979D         2   \n",
       "4                     9          L5 IT        #008A61         2   \n",
       "\n",
       "              class_label class_color  \n",
       "cluster_id                             \n",
       "0           Glutamatergic     #27AAE1  \n",
       "1           Glutamatergic     #27AAE1  \n",
       "2           Glutamatergic     #27AAE1  \n",
       "3           Glutamatergic     #27AAE1  \n",
       "4           Glutamatergic     #27AAE1  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cldf = utils.read_visp_npp_cldf()\n",
    "cldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell import  analysis, plot_utils\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "principalComponents = pca.fit_transform(vectors)\n",
    "pca_data = analysis.summarize_walk_embedding_results(gensim_dict={\"model\": principalComponents},\n",
    "                                                 index = [str(i) for i in range(93)],\n",
    "                                                 ndim=3, \n",
    "                                                 cl_df=cldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.Axes3DSubplot at 0x1ae31d9cd0>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt5\n",
    "plot_utils.plot_embedding(data=pca_data, cl_df=cldf, plot_dim=3, plot_size=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py374",
   "language": "python",
   "name": "py374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
