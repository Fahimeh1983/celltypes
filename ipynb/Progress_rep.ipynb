{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emitter Receiver model:\n",
    "\n",
    "<img src=\"./models_pic/E_R_model_linear.png\" alt=\"drawing\" width=\"900\"/>\n",
    "\n",
    "In this model, each arm is reconstructing an embedding. One for emitter roles and the other arm for the receiver roles. \n",
    "\n",
    "## Loss:\n",
    "### First term: Emitter_receiver_loss\n",
    "For this term, in the example that we have in the image, we compute the distance between emitter i ($E_i$) and receiver j ($R_j$) and the distance between $E_j$ and $R_k$. This terms are computed right after encoder. we call this term Emitter_receiver_loss:\n",
    "\n",
    "$$\n",
    "Batch\\_averaged\\_squared\\_distance = \\frac {1}{batch\\_size}\\sum_{batch\\_size}(distance^2(E_i, R_j) + distance^2(E_j, R_k))\n",
    "$$\n",
    "\n",
    "In order to prevent collapse. We Compute find the minimum variance (using svd) in all dimensions of the latent space and we call this $\\gamma$ and we divide the Emitter_receiver_loss term by this factor:\n",
    "$$\n",
    "Emitter\\_receiver\\_loss = \\frac {1}{\\gamma} Batch\\_averaged\\_squared\\_distance\n",
    "$$\n",
    "\n",
    "### Second term: AE_loss\n",
    "Both arms are suppose to reconstruct the middle node (j in this example). We use binary cross entropy (BCE) loss for this purpose:\n",
    "$$\n",
    "AE\\_loss = \\sum_{batch\\_size} BCE(p1, y1) + BCE(p2, y2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "Loss = Emitter\\_receiver\\_loss + \\lambda * AE\\_loss\n",
    "$$\n",
    "\n",
    "$\\lambda$ is a parameter to tune the contribuiton of the second term in the total loss.\n",
    "\n",
    "## Results: \n",
    "### Toy model 11 nodes\n",
    "<img src=\"./models_pic/Adj_11nodes.png\" alt=\"drawing\" width=\"450\"/>\n",
    "\n",
    "The following parameters were used for training: \n",
    "w (window_size) = 1, embedding_size = 2, learning_rate = 0.0001, $\\lambda$=0.5\n",
    "\n",
    "<img src=\"./models_pic/11nodes_emb.png\" alt=\"drawing\" width=\"450\"/>\n",
    "\n",
    "<img src=\"./models_pic/11nodes_nandcg.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "<img src=\"./models_pic/11nodes_svd.png\" alt=\"drawing\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results: \n",
    "### NPP \n",
    "\n",
    "<img src=\"./models_pic/Adj_npp.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "The following parameters were used for training: \n",
    "w (window_size) = 1, embedding_size = 3, learning_rate = 0.0001, $\\lambda$=0.5\n",
    "\n",
    "<img src=\"./models_pic/npp_emb.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "<img src=\"./models_pic/npp_nandcg.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "<img src=\"./models_pic/npp_svd.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "<img src=\"./models_pic/npp_final_ndcg.png\" alt=\"drawing\" width=\"1200\"/>\n",
    "\n",
    "For example node 26 (L6 CT VISp Gpr139) has a ndcg@5 score of ~0.95, lets see what are the predictions:\n",
    "\n",
    "<img src=\"./models_pic/npp_good_prediction.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "And the closest nodes based on adj matrix are:\n",
    "\n",
    "<img src=\"./models_pic/npp_good_adj.png\" alt=\"drawing\" width=\"1200\"/>\n",
    "\n",
    "\n",
    "For example node 16 (L5 PT VISp C1ql2 Ptgfr) has a ndcg@5 score of ~0.75, lets see what are the predictions:\n",
    "\n",
    "<img src=\"./models_pic/npp_interm_prediction.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "And the closest nodes based on adj matrix are:\n",
    "\n",
    "<img src=\"./models_pic/npp_interm_adj.png\" alt=\"drawing\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear encoder and non-linear decoder- model1: \n",
    "\n",
    "<img src=\"./models_pic/E_R_model_non_linear1.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "## Results\n",
    "### Toy model 11 nodes\n",
    "\n",
    "<img src=\"./models_pic/11nodes_nandcg_model1.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "<img src=\"./models_pic/11nodes_svd_model1.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPP\n",
    "\n",
    "<img src=\"./models_pic/npp_emb_model1.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "<img src=\"./models_pic/npp_nandcg_model1.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<img src=\"./models_pic/npp_svd_model1.png\" alt=\"drawing\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear encoder and non-linear decoder- model1: \n",
    "\n",
    "<img src=\"./models_pic/E_R_model_non_linear2.png\" a-lt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "## Results\n",
    "### NPP \n",
    "<img src=\"./models_pic/npp_nandcg_model2.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "<img src=\"./models_pic/npp_svd_model2.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py374",
   "language": "python",
   "name": "py374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
